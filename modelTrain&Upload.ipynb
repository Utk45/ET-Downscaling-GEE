{"cells":[{"cell_type":"markdown","metadata":{"id":"rZQMqxBRqjg0"},"source":["### 1. Install Dependencies, Import required Libraries and authenticate with Earth engine"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pk9zMYryqjg3"},"outputs":[],"source":["!pip install geemap"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n0811BIbwbsX"},"outputs":[],"source":["from os.path import isfile\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.svm import SVR\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n","import geemap\n","from geemap import ml\n","import ee\n","from google.colab import drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V85fxWBkwbsa"},"outputs":[],"source":["geemap.ee_initialize()"]},{"cell_type":"markdown","metadata":{"id":"RaXlSLTMqjg5"},"source":["## 2. Data Extraction:\n","\n","* Extract Training and Validation data from Drive\n","* Sample x-y points uniformly from dataset\n","* Store it in `x_train, y_train, x_test, y_test` for train and validating the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SiRqjvkRqjg5"},"outputs":[],"source":["drive.mount('/content/gdrive')\n","gdrive_pref = '/content/gdrive/My Drive/'"]},{"cell_type":"markdown","metadata":{"id":"TYIqSUBoqjg5"},"source":["Compute the names of folders to be used"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60uw1qqzwbsb"},"outputs":[],"source":["folder_pref = './AEZ_datasets_train_'\n","areas = np.arange(1, 11)\n","folders = np.char.add(folder_pref, areas.astype(str))\n","print(folders)"]},{"cell_type":"markdown","metadata":{"id":"PEYmyrY9qjg6"},"source":["Using the naming convention compute the names of the files to be used:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FUOVi6oOwbsb"},"outputs":[],"source":["years = np.arange(2016, 2023)\n","seasons = np.array(['Rabi_1','Kharif_1','Zaid_1'])\n","filenames = np.array([])\n","for year in years:\n","    for season in seasons:\n","        filenames = np.append(filenames, str(year) + '_' + season)\n","print(filenames)"]},{"cell_type":"markdown","metadata":{"id":"pcEMBfiHqjg7"},"source":["Append the file names paths to the dataset_paths array"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"s6AD2Xxpwbsc","outputId":"b3d1fbec-9d30-4ab0-8240-f940c120cd12"},"outputs":[{"data":{"text/html":["\n","            <style>\n","                .geemap-dark {\n","                    --jp-widgets-color: white;\n","                    --jp-widgets-label-color: white;\n","                    --jp-ui-font-color1: white;\n","                    --jp-layout-color2: #454545;\n","                    background-color: #383838;\n","                }\n","                    \n","                .geemap-dark .jupyter-button {\n","                    --jp-layout-color3: #383838;\n","                }\n","                \n","                .geemap-colab {\n","                    background-color: var(--colab-primary-surface-color, white);\n","                }\n","                    \n","                .geemap-colab .jupyter-button {\n","                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n","                }\n","            </style>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["dataset_paths = np.array([])\n","for folder in folders:\n","    for filename in filenames:\n","        dataset_paths = np.append(dataset_paths, gdrive_pref+folder + '/' + filename + '.csv')"]},{"cell_type":"markdown","metadata":{"id":"L0OJLEjLqjg7"},"source":["Append the relevant filenames to train-path array and val-path array"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"lySKt8j2wbsc","outputId":"df37c83f-3812-433e-9a1c-93dcfd8c07b0"},"outputs":[{"data":{"text/html":["\n","            <style>\n","                .geemap-dark {\n","                    --jp-widgets-color: white;\n","                    --jp-widgets-label-color: white;\n","                    --jp-ui-font-color1: white;\n","                    --jp-layout-color2: #454545;\n","                    background-color: #383838;\n","                }\n","                    \n","                .geemap-dark .jupyter-button {\n","                    --jp-layout-color3: #383838;\n","                }\n","                \n","                .geemap-colab {\n","                    background-color: var(--colab-primary-surface-color, white);\n","                }\n","                    \n","                .geemap-colab .jupyter-button {\n","                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n","                }\n","            </style>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["train_data_path = np.array([])\n","val_data_path = np.array([])\n","for dataset_path in dataset_paths:\n","    year = dataset_path.split('/')[6].split('_')[0]\n","    if(int(year) == 2022):\n","        val_data_path = np.append(val_data_path, dataset_path)\n","    else:\n","        train_data_path = np.append(train_data_path, dataset_path)"]},{"cell_type":"markdown","metadata":{"id":"thrdDlekqjg8"},"source":["Extract headers from the first file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i_yzcJDJqjg8"},"outputs":[],"source":["headers = np.array(pd.read_csv(train_data_path[0]).columns)"]},{"cell_type":"markdown","metadata":{"id":"WBfTUDdeqjg8"},"source":["Extract the data from the files and store in train_data and val_data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tIDgrcS5wbsc"},"outputs":[],"source":["train_data = np.array([])\n","for data_path in train_data_path:\n","    if(isfile(data_path)):\n","        data = pd.read_csv(data_path)\n","        data = np.array(data)\n","        if(train_data.size == 0):\n","            train_data = data\n","        else:\n","            train_data = np.vstack((train_data, data))\n","    else:\n","        print(data_path + ' does not exist')\n","print(train_data.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"54R6Yb-Xwbsc"},"outputs":[],"source":["val_data = np.array([])\n","for data_path in val_data_path:\n","    if(isfile(data_path)):\n","        data = pd.read_csv(data_path)\n","        data = np.array(data)\n","        if(val_data.size == 0):\n","            val_data = data\n","        else:\n","            val_data = np.vstack((val_data, data))\n","    else:\n","        print(data_path + ' does not exist')\n","print(val_data.shape)"]},{"cell_type":"markdown","metadata":{"id":"-QoSpBhuqjg9"},"source":["Remove features containing nan values, to find the corrupt headers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3TXC4jkiwbse"},"outputs":[],"source":["indices = np.argwhere(np.isnan(train_data))\n","indices = np.unique(indices[:, 1])\n","\n","corrupt_headers = headers[indices]\n","print(corrupt_headers)\n","\n","indix = np.argwhere(np.isnan(val_data))\n","indix = np.unique(indix[:, 1])\n","\n","train_data = np.delete(train_data, indices, 1)\n","val_data = np.delete(val_data, indix, 1)\n","\n","# output the size of the train_data and val_data\n","\n","print(train_data.shape)\n","print(val_data.shape)\n"]},{"cell_type":"markdown","metadata":{"id":"bm7Lk9-xqjg9"},"source":["Extract labels and feature names (required for converting random forest regressor to strings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qt3UvMgzqjg9"},"outputs":[],"source":["labels = headers[-1]\n","feature_names = np.array([])\n","for header in headers[:-1]:\n","    if header not in corrupt_headers:\n","        feature_names = np.append(feature_names, header)\n","print(feature_names)\n","print(len(feature_names))\n","print(labels)"]},{"cell_type":"markdown","metadata":{"id":"Jps3YuEKqjg9"},"source":["Extract the train_data_x, train_data_y, val_data_x, val_data_y from train_data and val_data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"jLu89eWlwbse","outputId":"6374997e-53b7-47a6-c7a5-293950ce9b66"},"outputs":[{"data":{"text/html":["\n","            <style>\n","                .geemap-dark {\n","                    --jp-widgets-color: white;\n","                    --jp-widgets-label-color: white;\n","                    --jp-ui-font-color1: white;\n","                    --jp-layout-color2: #454545;\n","                    background-color: #383838;\n","                }\n","                    \n","                .geemap-dark .jupyter-button {\n","                    --jp-layout-color3: #383838;\n","                }\n","                \n","                .geemap-colab {\n","                    background-color: var(--colab-primary-surface-color, white);\n","                }\n","                    \n","                .geemap-colab .jupyter-button {\n","                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n","                }\n","            </style>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["train_data_x = train_data[:, :-1]\n","train_data_y = train_data[:, -1]\n","\n","val_data_x = val_data[:, :-1]\n","val_data_y = val_data[:, -1]"]},{"cell_type":"markdown","metadata":{"id":"RdNkB3HQqjg9"},"source":["RUN THIS CELL IF THERE IS STORAGE ISSUE, THIS WILL DELETE UNNECESSARY VARIABLES THAT WOULD NOT BE REQUIRED IN FURTHER CELLS"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"ZObxQX1hwbse","outputId":"afc81965-019c-4d4f-8eee-a0d648b45692"},"outputs":[{"data":{"text/html":["\n","            <style>\n","                .geemap-dark {\n","                    --jp-widgets-color: white;\n","                    --jp-widgets-label-color: white;\n","                    --jp-ui-font-color1: white;\n","                    --jp-layout-color2: #454545;\n","                    background-color: #383838;\n","                }\n","                    \n","                .geemap-dark .jupyter-button {\n","                    --jp-layout-color3: #383838;\n","                }\n","                \n","                .geemap-colab {\n","                    background-color: var(--colab-primary-surface-color, white);\n","                }\n","                    \n","                .geemap-colab .jupyter-button {\n","                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n","                }\n","            </style>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["del train_data\n","del val_data\n","del folder_pref\n","del areas\n","del folders\n","del years\n","del seasons\n","del filenames\n","del dataset_paths\n","del train_data_path\n","del val_data_path"]},{"cell_type":"markdown","metadata":{"id":"IH6E1VVPqjg-"},"source":["PURE TRAIN DATA (SAMPLE RANDOMLY N POINTS FOR TRAINING AND STORE IN x_train AND y_train):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2LseGwdwbse"},"outputs":[],"source":["N = 200000\n","\n","shuffle_indices = np.arange(train_data_x.shape[0])\n","np.random.shuffle(shuffle_indices)\n","train_x = train_data_x[shuffle_indices]\n","train_y = train_data_y[shuffle_indices]\n","x_train = train_x[:N]\n","y_train = train_y[:N]\n","\n","#verify the size of y_train\n","print(len(y_train))"]},{"cell_type":"markdown","metadata":{"id":"RjJ4BGH8qjg-"},"source":[" PURE VALIDATION DATA (SAMPLE RANDOMLY M POINTS FOR VALIDATION AND STORE IN x_test AND y_test):\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"XMWtT0FPwbse","outputId":"7b5e1359-7cad-43fb-c744-7e9a2a621b2a"},"outputs":[{"data":{"text/html":["\n","            <style>\n","                .geemap-dark {\n","                    --jp-widgets-color: white;\n","                    --jp-widgets-label-color: white;\n","                    --jp-ui-font-color1: white;\n","                    --jp-layout-color2: #454545;\n","                    background-color: #383838;\n","                }\n","                    \n","                .geemap-dark .jupyter-button {\n","                    --jp-layout-color3: #383838;\n","                }\n","                \n","                .geemap-colab {\n","                    background-color: var(--colab-primary-surface-color, white);\n","                }\n","                    \n","                .geemap-colab .jupyter-button {\n","                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n","                }\n","            </style>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["shuffle_indices = np.arange(val_data_x.shape[0])\n","\n","np.random.shuffle(shuffle_indices)\n","val_x = val_data_x[shuffle_indices]\n","val_y = val_data_y[shuffle_indices]\n","x_test = val_x[:20000]\n","y_test = val_y[:20000]"]},{"cell_type":"markdown","metadata":{"id":"m-bDxUBoqjg-"},"source":["## 3. Train and Assess the model\n","* Train `rf_model` on x_train, y_train (train data points)\n","* Get the predictions for train and test data\n","* Output different metrics on these predictions such as `rmse, nrmse, R2_score`\n","* Plot the scatter plots of true values v/s predicted values"]},{"cell_type":"markdown","metadata":{"id":"HXW7T9GJqjg-"},"source":["Use Random Forest Regressor (change the parameters as required) and store the model in rf_model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oqHlzsqVwbsf"},"outputs":[],"source":["\n","rf_model = RandomForestRegressor(max_depth=10, random_state=0, n_estimators=5,n_jobs=-1)\n","rf_model.fit(x_train, y_train)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QNFoE6pcwbsf"},"outputs":[],"source":["y_pred = rf_model.predict(x_test)           # predict the values of y_test using the model (validation output stored in y_pred)\n","y_pred_train = rf_model.predict(x_train)    # predict the values of y_train using the model (training output stored in y_pred_train)"]},{"cell_type":"markdown","metadata":{"id":"0oNxnL78qjg_"},"source":["Compute the metrics for the model (mse, rmse, nrmse, nmse)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KXoDZHHfwbsg"},"outputs":[],"source":["testsize = x_test.shape[0]\n","print(f'Test size: {testsize}')\n","mse = mean_squared_error(y_test, y_pred)\n","mse0 = mean_squared_error(y_test, np.zeros(testsize))\n","ymean = np.mean(y_pred)\n","print(f'mean of pred: {ymean}')\n","print(f'mse: {mse}')\n","rmse = np.sqrt(mse)\n","print(f'rmse: {rmse}')\n","print(f'nmse: {mse/mse0}')\n","nrmse = rmse/ymean\n","print(f'nrmse: {nrmse}')\n","print(ymean)"]},{"cell_type":"markdown","metadata":{"id":"_Wu6K4NHqjg_"},"source":["Compute R2 score of the model on Train and Validation data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t-iNS24Jwbsg"},"outputs":[],"source":["\n","r2_train = r2_score(y_train, y_pred_train)\n","print(f'r2_train: {r2_train}')\n","\n","r2_val = r2_score(y_test, y_pred)\n","print(f'r2_validation: {r2_val}')"]},{"cell_type":"markdown","metadata":{"id":"8onM9SqmqjhA"},"source":["#### Plots for Accuracy Assessment:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vSNTW2WFwbsg"},"outputs":[],"source":["y_actual = y_train\n","\n","plt.scatter(y_actual, y_pred_train, s=20, alpha=0.7, edgecolors='w', linewidth=0.5)\n","\n","# Plot the 45-degree line\n","plt.plot([min(y_actual), max(y_actual)], [min(y_actual), max(y_actual)], color='red', linestyle='--')\n","\n","# Set axis labels\n","plt.xlim(0,700)\n","plt.ylim(0,700)\n","plt.xlabel('Actual Values')\n","plt.ylabel('Predicted Values')\n","\n","# Set plot title\n","plt.title('Scatter plot of Actual vs. Predicted (Training Data)')\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cThTKMQewbsg"},"outputs":[],"source":["# Plot the scatter plot of Actual vs. Predicted (Validation Data)\n","\n","y_actual = y_test\n","plt.scatter(y_actual, y_pred, s=20, alpha=0.7, edgecolors='w', linewidth=0.5)\n","\n","# Plot the 45-degree line\n","plt.plot([min(y_actual), max(y_actual)], [min(y_actual), max(y_actual)], color='red', linestyle='--')\n","\n","# Set axis labels\n","plt.xlim(0,700)\n","plt.ylim(0,700)\n","plt.xlabel('Actual Values')\n","plt.ylabel('Predicted Values')\n","\n","# Set plot title\n","plt.title('Scatter plot of Actual vs. Predicted (Validation Data)')\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"UVV_1TPzqjhA"},"source":["## 4. Uploading trained model to Google Earth Engine:\n","1. Serialise the random forest model to a list of strings (where each string represents a decision tree)\n","2. Convert the list of strings to a `ee.FeatureCollection`\n","3. Export the `ee.FeatureCollection` to Google Earth Engine as an asset"]},{"cell_type":"markdown","metadata":{"id":"WpzEKporqjhA"},"source":["Serialise random forest to strings and store it in rf_strings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LmaPPFJdqjhA"},"outputs":[],"source":["\n","rf_strings = ml.rf_to_strings(rf_model, feature_names, output_mode='regression', processes=6)\n"]},{"cell_type":"markdown","metadata":{"id":"VnpgRqo7qjhA"},"source":["To convert the list of strings to a ee.FeatureCollection :\n","1. Convert the list of strings to a list of dummy ee.Features (with any ~NON NULL~ geometry and property `tree` set as the string representing the tree)\n","2. Convert this list of features to a ee.FeatureCollections and store it in fc_string"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"HPo5ly4grNtc","outputId":"7a4d081c-f4f9-4376-d75e-449a26f3f6ab"},"outputs":[{"data":{"text/html":["\n","            <style>\n","                .geemap-dark {\n","                    --jp-widgets-color: white;\n","                    --jp-widgets-label-color: white;\n","                    --jp-ui-font-color1: white;\n","                    --jp-layout-color2: #454545;\n","                    background-color: #383838;\n","                }\n","                    \n","                .geemap-dark .jupyter-button {\n","                    --jp-layout-color3: #383838;\n","                }\n","                \n","                .geemap-colab {\n","                    background-color: var(--colab-primary-surface-color, white);\n","                }\n","                    \n","                .geemap-colab .jupyter-button {\n","                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n","                }\n","            </style>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["dummy_feature = ee.Feature(ee.Geometry.Point([-114.318, 38.985]));\n","treeStrings = []\n","for dt in rf_strings:\n","  feat = dummy_feature.set('tree', dt)\n","  treeStrings.append(feat)\n","fc_string = ee.FeatureCollection(treeStrings)"]},{"cell_type":"markdown","metadata":{"id":"qg6ZJPd2qjhB"},"source":["Export the `ee.FeatureCollection` to earth engine asset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZ5cAQwqxa7P"},"outputs":[],"source":["asset_name = 'rf_demo_7'\n","task_name = asset_name+'_task'\n","asset_path= 'projects/vatsal-stiti/assets/'+asset_name\n","task = ee.batch.Export.table.toAsset(fc_string,task_name,asset_path);\n","task.start()"]},{"cell_type":"markdown","metadata":{"id":"jvXiBPjnqjhB"},"source":["## 5. Downloading the Model in GEE and using it to inference ET:\n","To download the model from GEE asset and load it as a classifier use this code snippet in Google Earth Engine Editor:\n","```\n","var RandomForestasFeatCollection = ee.FeatureCollection(assetName).aggregate_array('tree').aside(print);\n","var classifier = ee.Classifier.decisionTreeEnsemble(RandomForestasFeatCollection);\n","```\n","Replace assetName with the path of asset that contains the model. The code is available in the script at: `Vatsal_Stiti/FinalPipelineScripts/InferenceETFromModelAsset`. Use this script to predict ET of any area on a given date."]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}